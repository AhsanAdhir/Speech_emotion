{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fehE3ivnWiio"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import glob\n",
        "\n",
        "# === Function to summarize each feature matrix ===\n",
        "def summarize_feature(feat):\n",
        "    return np.hstack([\n",
        "        np.mean(feat, axis=1),\n",
        "        np.std(feat, axis=1),\n",
        "        np.min(feat, axis=1),\n",
        "        np.max(feat, axis=1)\n",
        "    ])\n",
        "\n",
        "# === Load features from MATLAB .mat files ===\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# All .mat files assumed to be in same folder\n",
        "feature_files = sorted(glob.glob('features_sample*.mat'))\n",
        "\n",
        "for f in feature_files:\n",
        "    data = loadmat(f)\n",
        "    mfcc = data['mfcc']\n",
        "    centroid = data['centroid']\n",
        "    rolloff = data['rolloff']\n",
        "    mel = data['mel']\n",
        "    chroma = data['chroma']\n",
        "\n",
        "    # Combine summarized features into one vector\n",
        "    feature_vector = np.hstack([\n",
        "        summarize_feature(mfcc),\n",
        "        summarize_feature(centroid),\n",
        "        summarize_feature(rolloff),\n",
        "        summarize_feature(mel),\n",
        "        summarize_feature(chroma)\n",
        "    ])\n",
        "    X.append(feature_vector)\n",
        "\n",
        "# Load labels from labels.txt\n",
        "with open('labels.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        y.append(line.strip())\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# === Encode string labels into numeric values ===\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# === Train-test split (80% training, 20% testing) ===\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=1, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# === Create and train SVM model with RBF kernel ===\n",
        "classifier = SVC(kernel='rbf', random_state=1, C=1, gamma='auto')\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# === Predict on test set ===\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "# === Confusion matrix and accuracy calculation ===\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "accuracy = float(cm.diagonal().sum()) / len(y_test)\n",
        "print(f\"Model accuracy is: {accuracy * 100:.2f}%\")\n"
      ]
    }
  ]
}